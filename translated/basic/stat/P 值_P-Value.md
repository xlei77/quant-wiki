---
{}
---

## What is P-value?

In statistics, P-value is defined as the probability of obtaining a value equal to or greater than the observed result, given that the null hypothesis is true.

As an alternative to rejection points, P-value provides the minimum significance level at which the null hypothesis can be rejected. A smaller P-value indicates stronger evidence supporting the alternative hypothesis.

P-values are frequently used to enhance the credibility of government agency research or reports. For example, the U.S. Census Bureau requires that any analysis with a P-value greater than 0.10 must be accompanied by a statement indicating that the difference is not statistically significant from zero. The Census Bureau also has standards regarding acceptable P-values for different publications.

### Key Points

- P-value is a statistical measure used to validate the relationship between hypotheses and observed data.
- P-value measures the probability of obtaining the observed results, assuming the null hypothesis is true.
- The smaller the P-value, the more statistically significant the observed difference is.
- A P-value of 0.05 or lower is typically considered statistically significant.
- P-values can be used as an alternative to hypothesis testing or in conjunction with pre-selected confidence levels.

## Understanding P-values

P-values are typically calculated using statistical software or P-value tables based on hypothesized or known probability distributions. While sample size affects the reliability of observed data, the hypothesis testing method for P-values specifically involves calculating the P-value based on the deviation between the observed value and the chosen reference value, while considering the statistical probability distribution. The larger the difference between two values, the lower the P-value.

Mathematically, P-values are calculated by integrating the area under a probability distribution curve, including all statistical values that are at least as far from the reference value as the observed value, compared to the total area under the probability distribution curve. Standard deviation is crucial in this calculation as it quantifies the degree of dispersion between data points and the mean.

The calculation of P-values depends on the type of test being performed. Three types of tests describe the position on the probability distribution curve: left-tailed test, right-tailed test, or two-tailed test. In each case, degrees of freedom play a key role in determining the distribution shape and calculating the P-value.

In simple terms, the larger the difference between two observed values, the less likely that difference is due to random chance, which will be reflected in a lower P-value.

## Application of P-values in Hypothesis Testing

The application of P-values in hypothesis testing uses calculated probabilities to determine whether there is evidence to reject the null hypothesis. This determination largely depends on the test statistic, which summarizes the information from the sample relevant to the hypothesis being tested. The null hypothesis, also called the hypothesis, is an initial statement about a population (or data-generating process). The alternative hypothesis states whether the population parameter differs from the population parameter value stated in the hypothesis.

In practice, significance levels are usually declared in advance to determine how small the P-value needs to be to reject the null hypothesis. Since different researchers may use different significance levels when examining a problem, readers might find it difficult to compare the results of two different tests. P-values provide a solution to this issue.

**Important Note:** Even if a P-value is small, it doesn't necessarily prove statistical significance, as there remains a possibility that the observed data could be a chance result. Only through repeated experiments or studies can a relationship be confirmed as statistically significant.

For example, suppose studies comparing returns of two specific assets are conducted by different researchers using the same data but different significance levels. The researchers might reach opposite conclusions about whether the two assets are different.

If one researcher uses a 90% confidence level, while another researcher requires a 95% confidence level to reject the null hypothesis, and the observed P-value between the two returns is 0.08 (equivalent to a 92% confidence level), then the first researcher would find the difference between the two assets statistically significant, while the second would not.

To avoid this problem, researchers can report the P-value of the hypothesis test, allowing readers to interpret statistical significance themselves. This is known as the P-value approach to hypothesis testing. Independent observers can note the P-value and decide for themselves whether this represents a statistically significant difference.

## P-Value Example

An investor claims that their portfolio's performance is equivalent to the S&P 500 index. To verify this, the investor conducts a two-tailed test.

The null hypothesis assumes that the portfolio's returns are equivalent to the S&P 500 index returns over a specific period, while the alternative hypothesis states that the portfolio returns and S&P 500 returns are not equivalentâ€”if the investor were conducting a one-tailed test, the alternative hypothesis would state that the portfolio returns are either less than or greater than the S&P 500 returns.

P-value hypothesis testing doesn't necessarily use a pre-selected confidence level to determine when an investor should reset the null hypothesis that returns are equivalent. Instead, it provides a method to measure the amount of evidence to reject the null hypothesis. The smaller the P-value, the stronger the evidence against the null hypothesis.

Therefore, if an investor finds a P-value of 0.001, there is strong evidence against the null hypothesis, and the investor can confidently conclude that the portfolio returns are not the same as the S&P 500 index returns.

Although this doesn't provide an exact threshold for when to accept or reject the null hypothesis, it does have another very practical advantage. P-value hypothesis testing provides a direct way for investors to compare multiple different types of investments or portfolios against benchmarks such as the S&P 500 index.

For example, with two portfolios A and B having P-values of 0.10 and 0.01 respectively when compared to the S&P 500, an investor can be more confident that Portfolio B, with the lower P-value, will actually demonstrate more consistent results.

## Is a P-value of 0.05 Significant?

A P-value less than 0.05 is typically considered statistically significant, in which case the null hypothesis should be rejected. A P-value greater than 0.05 indicates that the deviation from the null hypothesis is not statistically significant, therefore the null hypothesis is not rejected.

## What does a P-value of 0.001 mean?

A P-value of 0.001 indicates that if the null hypothesis being tested is indeed true, the chance of observing a result at least as extreme as the one observed is one in a thousand. This leads the observer to reject the null hypothesis, because either an extremely rare data result has been observed, or the null hypothesis is incorrect.

## How to Compare P-values Between Two Different Hypothesis Tests?

If you have two different results, one with a P-value of 0.04 and another with a P-value of 0.06, the result with a P-value of 0.04 would be considered statistically more significant than the result with a P-value of 0.06. Beyond this simple example, you can compare a result with a P-value of 0.04 to one with a P-value of 0.001. Both are statistically significant, but the example with 0.001 provides stronger evidence against the null hypothesis.

## Summary

The P-value is used to measure the significance of observed data. When researchers identify an apparent relationship between two variables, there is always a possibility that this correlation could be coincidental. P-value calculations help determine whether the observed relationship is likely to have occurred by random chance.

## References

[1] U.S. Census Bureau. "[Statistical Quality Standard E1: Analyzing Data](https://www.census.gov/about/policies/quality/standards/standarde1.html)."