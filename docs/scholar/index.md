<p align="center"><h1 align="center">üåü QUANT-SCHOLAR üåü</h1><h2 align="center">Automatically Quantitative Finance Papers List</h2></p>                        <p align="center"><img src="https://raw.githubusercontent.com/LLMQuant/quant-scholar/main/asset/icon.png" width="180"></p>                        
 
## üö© Updated on 2025.03.14 
<details>
  <summary><strong>üìú Contents</strong></summary>
  <ol>
    <li><a href=#-machine-learning-in-finance>üìå Machine Learning in Finance</a></li>
    <li><a href=#-deep-learning-in-finance>üìå Deep Learning in Finance</a></li>
    <li><a href=#-reinforcement-learning-in-finance>üìå Reinforcement Learning in Finance</a></li>
    <li><a href=#-time-series-forecasting>üìå Time Series Forecasting</a></li>
  </ol>
</details>

## üìå Machine Learning in Finance

| üìÖ Publish Date | üìñ Title | üë®‚Äçüíª Authors | üîó PDF | üíª Code | üí¨ Comment | üìú Abstract |
|:--------------:|:----------------------------|:------------------|:------:|:------:|:-------:|:--------|
| 2025-03-06 | Matrix H-theory approach to stock market fluctuations | Luan M. T. de Moraes, Ant√¥nio M. S. Macedo, Raydonal Ospina et.al. | [2503.08697](http://arxiv.org/abs/2503.08697) |  | 26 pages, 10 figures. Published on Physical Review E | <details><summary>Abstract (click to expand)</summary>We introduce matrix H theory, a framework for analyzing collective behavior arising from multivariate stochastic processes with hierarchical structure. The theory models the joint distribution of the multiple variables (the measured signal) as a compound of a large-scale multivariate distribution with the distribution of a slowly fluctuating background. The background is characterized by a hierarchical stochastic evolution of internal degrees of freedom, representing the correlations between stocks at different time scales. As in its univariate version, the matrix H-theory formalism also has two universality classes: Wishart and inverse Wishart, enabling a concise description of both the background and the signal probability distributions in terms of Meijer G-functions with matrix argument. Empirical analysis of daily returns of stocks within the S&P500 demonstrates the effectiveness of matrix H theory in describing fluctuations in stock markets. These findings contribute to a deeper understanding of multivariate hierarchical processes and offer potential for developing more informed portfolio strategies in financial markets.</details> |
| 2025-03-05 | Multimodal Stock Price Prediction: A Case Study of the Russian Securities Market | Kasymkhan Khubiev, Mikhail Semenov et.al. | [2503.08696](http://arxiv.org/abs/2503.08696) |  | NSCF-2024, PROGRAM SYSTEMS: THEORY AND APPLICATIONS | <details><summary>Abstract (click to expand)</summary>Classical asset price forecasting methods primarily rely on numerical data, such as price time series, trading volumes, limit order book data, and technical analysis indicators. However, the news flow plays a significant role in price formation, making the development of multimodal approaches that combine textual and numerical data for improved prediction accuracy highly relevant. This paper addresses the problem of forecasting financial asset prices using the multimodal approach that combines candlestick time series and textual news flow data. A unique dataset was collected for the study, which includes time series for 176 Russian stocks traded on the Moscow Exchange and 79,555 financial news articles in Russian. For processing textual data, pre-trained models RuBERT and Vikhr-Qwen2.5-0.5b-Instruct (a large language model) were used, while time series and vectorized text data were processed using an LSTM recurrent neural network. The experiments compared models based on a single modality (time series only) and two modalities, as well as various methods for aggregating text vector representations. Prediction quality was estimated using two key metrics: Accuracy (direction of price movement prediction: up or down) and Mean Absolute Percentage Error (MAPE), which measures the deviation of the predicted price from the true price. The experiments showed that incorporating textual modality reduced the MAPE value by 55%. The resulting multimodal dataset holds value for the further adaptation of language models in the financial sector. Future research directions include optimizing textual modality parameters, such as the time window, sentiment, and chronological order of news messages.</details> |
| 2025-03-02 | Liquidity-adjusted Return and Volatility, and Autoregressive Models | Qi Deng, Zhong-guo Zhou et.al. | [2503.08693](http://arxiv.org/abs/2503.08693) |  |  | <details><summary>Abstract (click to expand)</summary>We construct liquidity-adjusted return and volatility using purposely designed liquidity metrics (liquidity jump and liquidity diffusion) that incorporate additional liquidity information. Based on these measures, we introduce a liquidity-adjusted ARMA-GARCH framework to address the limitations of traditional ARMA-GARCH models, which are not effectively in modeling illiquid assets with high liquidity variability, such as cryptocurrencies. We demonstrate that the liquidity-adjusted model improves model fit for cryptocurrencies, with greater volatility sensitivity to past shocks and reduced volatility persistence of erratic past volatility. Our model is validated by the empirical evidence that the liquidity-adjusted mean-variance (LAMV) portfolios outperform the traditional mean-variance (TMV) portfolios.</details> |
| 2025-02-27 | Detecting Crypto Pump-and-Dump Schemes: A Thresholding-Based Approach to Handling Market Noise | Mahya Karbalaii et.al. | [2503.08692](http://arxiv.org/abs/2503.08692) |  |  | <details><summary>Abstract (click to expand)</summary>We propose a simple yet robust unsupervised model to detect pump-and-dump events on tokens listed on the Poloniex Exchange platform. By combining threshold-based criteria with exponentially weighted moving averages (EWMA) and volatility measures, our approach effectively distinguishes genuine anomalies from minor trading fluctuations, even for tokens with low liquidity and prolonged inactivity. These characteristics present a unique challenge, as standard anomaly-detection methods often over-flag negligible volume spikes. Our framework overcomes this issue by tailoring both price and volume thresholds to the specific trading patterns observed, resulting in a model that balances high true-positive detection with minimal noise.</details> |
| 2025-03-10 | Large language models in finance : what is financial sentiment? | Kemal Kirtac, Guido Germano et.al. | [2503.03612](http://arxiv.org/abs/2503.03612) |  |  | <details><summary>Abstract (click to expand)</summary>Financial sentiment has become a crucial yet complex concept in finance, increasingly used in market forecasting and investment strategies. Despite its growing importance, there remains a need to define and understand what financial sentiment truly represents and how it can be effectively measured. We explore the nature of financial sentiment and investigate how large language models (LLMs) contribute to its estimation. We trace the evolution of sentiment measurement in finance, from market-based and lexicon-based methods to advanced natural language processing techniques. The emergence of LLMs has significantly enhanced sentiment analysis, providing deeper contextual understanding and greater accuracy in extracting sentiment from financial text. We examine how BERT-based models, such as RoBERTa and FinBERT, are optimized for structured sentiment classification, while GPT-based models, including GPT-4, OPT, and LLaMA, excel in financial text generation and real-time sentiment interpretation. A comparative analysis of bidirectional and autoregressive transformer architectures highlights their respective roles in investor sentiment analysis, algorithmic trading, and financial decision-making. By exploring what financial sentiment is and how it is estimated within LLMs, we provide insights into the growing role of AI-driven sentiment analysis in finance.</details> |
| 2025-03-04 | VWAP Execution with Signature-Enhanced Transformers: A Multi-Asset Learning Approach | Remi Genet et.al. | [2503.02680](http://arxiv.org/abs/2503.02680) | **[link](https://github.com/remigenet/DynamicVWAPTransformer)** |  | <details><summary>Abstract (click to expand)</summary>In this paper I propose a novel approach to Volume Weighted Average Price (VWAP) execution that addresses two key practical challenges: the need for asset-specific model training and the capture of complex temporal dependencies. Building upon my recent work in dynamic VWAP execution arXiv:2502.18177, I demonstrate that a single neural network trained across multiple assets can achieve performance comparable to or better than traditional asset-specific models. The proposed architecture combines a transformer-based design inspired by arXiv:2406.02486 with path signatures for capturing geometric features of price-volume trajectories, as in arXiv:2406.17890. The empirical analysis, conducted on hourly cryptocurrency trading data from 80 trading pairs, shows that the globally-fitted model with signature features (GFT-Sig) achieves superior performance in both absolute and quadratic VWAP loss metrics compared to asset-specific approaches. Notably, these improvements persist for out-of-sample assets, demonstrating the model's ability to generalize across different market conditions. The results suggest that combining global parameter sharing with signature-based feature extraction provides a scalable and robust approach to VWAP execution, offering significant practical advantages over traditional asset-specific implementations.</details> |
| 2025-03-04 | Extrapolating the long-term seasonal component of electricity prices for forecasting in the day-ahead market | Katarzyna Chƒôƒá, Bartosz Uniejewski, Rafa≈Ç Weron et.al. | [2503.02518](http://arxiv.org/abs/2503.02518) |  |  | <details><summary>Abstract (click to expand)</summary>Recent studies provide evidence that decomposing the electricity price into the long-term seasonal component (LTSC) and the remaining part, predicting both separately, and then combining their forecasts can bring significant accuracy gains in day-ahead electricity price forecasting. However, not much attention has been paid to predicting the LTSC, and the last 24 hourly values of the estimated pattern are typically copied for the target day. To address this gap, we introduce a novel approach which extracts the trend-seasonal pattern from a price series extrapolated using price forecasts for the next 24 hours. We assess it using two 5-year long test periods from the German and Spanish power markets, covering the Covid-19 pandemic, the 2021/2022 energy crisis, and the war in Ukraine. Considering parsimonious autoregressive and LASSO-estimated models, we find that improvements in predictive accuracy range from 3\% to 15\% in terms of the root mean squared error and exceed 1\% in terms of profits from a realistic trading strategy involving day-ahead bidding and battery storage.</details> |
| 2025-03-01 | Understanding the Commodity Futures Term Structure Through Signatures | Hari P. Krishnan, Stephan Sturm et.al. | [2503.00603](http://arxiv.org/abs/2503.00603) |  | 19 pages, 1 figure | <details><summary>Abstract (click to expand)</summary>Signature methods have been widely and effectively used as a tool for feature extraction in statistical learning methods, notably in mathematical finance. They lack, however, interpretability: in the general case, it is unclear why signatures actually work. The present article aims to address this issue directly, by introducing and developing the concept of signature perturbations. In particular, we construct a regular perturbation of the signature of the term structure of log prices for various commodities, in terms of the convenience yield. Our perturbation expansion and rigorous convergence estimates help explain the success of signature-based classification of commodities markets according to their term structure, with the volatility of the convenience yield as the major discriminant.</details> |
| 2025-03-04 | Using quantile time series and historical simulation to forecast financial risk multiple steps ahead | Richard Gerlach, Antonio Naimoli, Giuseppe Storti et.al. | [2502.20978](http://arxiv.org/abs/2502.20978) |  |  | <details><summary>Abstract (click to expand)</summary>A method for quantile-based, semi-parametric historical simulation estimation of multiple step ahead Value-at-Risk (VaR) and Expected Shortfall (ES) models is developed. It uses the quantile loss function, analogous to how the quasi-likelihood is employed by standard historical simulation methods. The returns data are scaled by the estimated quantile series, then resampling is employed to estimate the forecast distribution one and multiple steps ahead, allowing tail risk forecasting. The proposed method is applicable to any data or model where the relationship between VaR and ES does not change over time and can be extended to allow a measurement equation incorporating realized measures, thus including Realized GARCH and Realized CAViaR type models. Its finite sample properties, and its comparison with existing historical simulation methods, are evaluated via a simulation study. A forecasting study assesses the relative accuracy of the 1% and 2.5% VaR and ES one-day-ahead and ten-day-ahead forecasting results for the proposed class of models compared to several competitors.</details> |
| 2025-02-26 | Corporate Fraud Detection in Rich-yet-Noisy Financial Graph | Shiqi Wang, Zhibo Zhang, Libing Fang et.al. | [2502.19305](http://arxiv.org/abs/2502.19305) | **[link](https://github.com/wangskyGit/KeHGN-R)** |  | <details><summary>Abstract (click to expand)</summary>Corporate fraud detection aims to automatically recognize companies that conduct wrongful activities such as fraudulent financial statements or illegal insider trading. Previous learning-based methods fail to effectively integrate rich interactions in the company network. To close this gap, we collect 18-year financial records in China to form three graph datasets with fraud labels. We analyze the characteristics of the financial graphs, highlighting two pronounced issues: (1) information overload: the dominance of (noisy) non-company nodes over company nodes hinders the message-passing process in Graph Convolution Networks (GCN); and (2) hidden fraud: there exists a large percentage of possible undetected violations in the collected data. The hidden fraud problem will introduce noisy labels in the training dataset and compromise fraud detection results. To handle such challenges, we propose a novel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage Learning ( ${\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to mitigate the information overload and effectively learns rich representations. The proposed model adopts a two-stage learning method to enhance robustness against hidden frauds. Extensive experimental results not only confirm the importance of interactions but also show the superiority of ${\rm KeGCN}_{R}$ over a number of strong baselines in terms of fraud detection effectiveness and robustness.</details> |
| 2025-02-25 | Recurrent Neural Networks for Dynamic VWAP Execution: Adaptive Trading Strategies with Temporal Kolmogorov-Arnold Networks | Remi Genet et.al. | [2502.18177](http://arxiv.org/abs/2502.18177) | **[link](https://github.com/remigenet/deepdynamicvwap)** |  | <details><summary>Abstract (click to expand)</summary>The execution of Volume Weighted Average Price (VWAP) orders remains a critical challenge in modern financial markets, particularly as trading volumes and market complexity continue to increase. In my previous work arXiv:2502.13722, I introduced a novel deep learning approach that demonstrated significant improvements over traditional VWAP execution methods by directly optimizing the execution problem rather than relying on volume curve predictions. However, that model was static because it employed the fully linear approach described in arXiv:2410.21448, which is not designed for dynamic adjustment. This paper extends that foundation by developing a dynamic neural VWAP framework that adapts to evolving market conditions in real time. We introduce two key innovations: first, the integration of recurrent neural networks to capture complex temporal dependencies in market dynamics, and second, a sophisticated dynamic adjustment mechanism that continuously optimizes execution decisions based on market feedback. The empirical analysis, conducted across five major cryptocurrency markets, demonstrates that this dynamic approach achieves substantial improvements over both traditional methods and our previous static implementation, with execution performance gains of 10 to 15% in liquid markets and consistent outperformance across varying conditions. These results suggest that adaptive neural architectures can effectively address the challenges of modern VWAP execution while maintaining computational efficiency suitable for practical deployment.</details> |
| 2025-02-25 | LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena | Tianmi Ma, Jiawei Du, Wenxin Huang et.al. | [2502.17967](http://arxiv.org/abs/2502.17967) | **[link](https://github.com/wekjsdvnm/agent-trading-arena)** |  | <details><summary>Abstract (click to expand)</summary>Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.</details> |
| 2025-02-24 | A data-driven econo-financial stress-testing framework to estimate the effect of supply chain networks on financial systemic risk | Jan Fialkowski, Christian Diem, Andr√°s Borsos et.al. | [2502.17044](http://arxiv.org/abs/2502.17044) | **[link](https://github.com/JanFialkowski/FSRI_Plus)** |  | <details><summary>Abstract (click to expand)</summary>Supply chain disruptions constitute an often underestimated risk for financial stability. As in financial networks, systemic risks in production networks arises when the local failure of one firm impacts the production of others and might trigger cascading disruptions that affect significant parts of the economy. Here, we study how systemic risk in production networks translates into financial systemic risk through a mechanism where supply chain contagion leads to correlated bank-firm loan defaults. We propose a financial stress-testing framework for micro- and macro-prudential applications that features a national firm level supply chain network in combination with interbank network layers. The model is calibrated by using a unique data set including about 1 million firm-level supply links, practically all bank-firm loans, and all interbank loans in a small European economy. As a showcase we implement a real COVID-19 shock scenario on the firm level. This model allows us to study how the disruption dynamics in the real economy can lead to interbank solvency contagion dynamics. We estimate to what extent this amplifies financial systemic risk. We discuss the relative importance of these contagion channels and find an increase of interbank contagion by 70% when production network contagion is present. We then examine the financial systemic risk firms bring to banks and find an increase of up to 28% in the presence of the interbank contagion channel. This framework is the first financial systemic risk model to take agent-level dynamics of the production network and shocks of the real economy into account which opens a path for directly, and event-driven understanding of the dynamical interaction between the real economy and financial systems.</details> |
| 2025-02-22 | Contrastive Similarity Learning for Market Forecasting: The ContraSim Framework | Nicholas Vinden, Raeid Saqur, Zining Zhu et.al. | [2502.16023](http://arxiv.org/abs/2502.16023) |  | 8 pages, 3 appendices | <details><summary>Abstract (click to expand)</summary>We introduce the Contrastive Similarity Space Embedding Algorithm (ContraSim), a novel framework for uncovering the global semantic relationships between daily financial headlines and market movements. ContraSim operates in two key stages: (I) Weighted Headline Augmentation, which generates augmented financial headlines along with a semantic fine-grained similarity score, and (II) Weighted Self-Supervised Contrastive Learning (WSSCL), an extended version of classical self-supervised contrastive learning that uses the similarity metric to create a refined weighted embedding space. This embedding space clusters semantically similar headlines together, facilitating deeper market insights. Empirical results demonstrate that integrating ContraSim features into financial forecasting tasks improves classification accuracy from WSJ headlines by 7%. Moreover, leveraging an information density analysis, we find that the similarity spaces constructed by ContraSim intrinsically cluster days with homogeneous market movement directions, indicating that ContraSim captures market dynamics independent of ground truth labels. Additionally, ContraSim enables the identification of historical news days that closely resemble the headlines of the current day, providing analysts with actionable insights to predict market trends by referencing analogous past events.</details> |
| 2025-02-21 | Multi-Agent Stock Prediction Systems: Machine Learning Models, Simulations, and Real-Time Trading Strategies | Daksh Dave, Gauransh Sawhney, Vikhyat Chauhan et.al. | [2502.15853](http://arxiv.org/abs/2502.15853) |  |  | <details><summary>Abstract (click to expand)</summary>This paper presents a comprehensive study on stock price prediction, leveragingadvanced machine learning (ML) and deep learning (DL) techniques to improve financial forecasting accuracy. The research evaluates the performance of various recurrent neural network (RNN) architectures, including Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRU), and attention-based models. These models are assessed for their ability to capture complex temporal dependencies inherent in stock market data. Our findings show that attention-based models outperform other architectures, achieving the highest accuracy by capturing both short and long-term dependencies. This study contributes valuable insights into AI-driven financial forecasting, offering practical guidance for developing more accurate and efficient trading systems.</details> |
| 2025-02-20 | Financial fraud detection system based on improved random forest and gradient boosting machine (GBM) | Tianzuo Hu et.al. | [2502.15822](http://arxiv.org/abs/2502.15822) |  |  | <details><summary>Abstract (click to expand)</summary>This paper proposes a financial fraud detection system based on improved Random Forest (RF) and Gradient Boosting Machine (GBM). Specifically, the system introduces a novel model architecture called GBM-SSRF (Gradient Boosting Machine with Simplified and Strengthened Random Forest), which cleverly combines the powerful optimization capabilities of the gradient boosting machine (GBM) with improved randomization. The computational efficiency and feature extraction capabilities of the Simplified and Strengthened Random Forest (SSRF) forest significantly improve the performance of financial fraud detection. Although the traditional random forest model has good classification capabilities, it has high computational complexity when faced with large-scale data and has certain limitations in feature selection. As a commonly used ensemble learning method, the GBM model has significant advantages in optimizing performance and handling nonlinear problems. However, GBM takes a long time to train and is prone to overfitting problems when data samples are unbalanced. In response to these limitations, this paper optimizes the random forest based on the structure, reducing the computational complexity and improving the feature selection ability through the structural simplification and enhancement of the random forest. In addition, the optimized random forest is embedded into the GBM framework, and the model can maintain efficiency and stability with the help of GBM's gradient optimization capability. Experiments show that the GBM-SSRF model not only has good performance, but also has good robustness and generalization capabilities, providing an efficient and reliable solution for financial fraud detection.</details> |
| 2025-02-21 | Network topology of the Euro Area interbank market | Ilias Aarab, Thomas Gottron et.al. | [2502.15611](http://arxiv.org/abs/2502.15611) |  | This is the preprint version of the paper published in: Aarab, I.,   Gottron, T. (2024). Network Topology of the Euro Area Interbank Market. In:   Mingione, M., Vichi, M., Zaccaria, G. (eds) *High-quality and Timely   Statistics*. CESS 2022. Studies in Theoretical and Applied Statistics.   Springer, Cham. https://doi.org/10.1007/978-3-031-63630-1_1 | <details><summary>Abstract (click to expand)</summary>The rapidly increasing availability of large amounts of granular financial data, paired with the advances of big data related technologies induces the need of suitable analytics that can represent and extract meaningful information from such data. In this paper we propose a multi-layer network approach to distill the Euro Area (EA) banking system in different distinct layers. Each layer of the network represents a specific type of financial relationship between banks, based on various sources of EA granular data collections. The resulting multi-layer network allows one to describe, analyze and compare the topology and structure of EA banks from different perspectives, eventually yielding a more complete picture of the financial market. This granular information representation has the potential to enable researchers and practitioners to better apprehend financial system dynamics as well as to support financial policies to manage and monitor financial risk from a more holistic point of view.</details> |
| 2025-02-21 | Clustered Network Connectedness: A New Measurement Framework with Application to Global Equity Markets | Bastien Buchwalter, Francis X. Diebold, Kamil Yilmaz et.al. | [2502.15458](http://arxiv.org/abs/2502.15458) |  |  | <details><summary>Abstract (click to expand)</summary>Network connections, both across and within markets, are central in countless economic contexts. In recent decades, a large literature has developed and applied flexible methods for measuring network connectedness and its evolution, based on variance decompositions from vector autoregressions (VARs), as in Diebold and Yilmaz (2014). Those VARs are, however, typically identified using full orthogonalization (Sims, 1980), or no orthogonalization (Koop, Pesaran, and Potter, 1996; Pesaran and Shin, 1998), which, although useful, are special and extreme cases of a more general framework that we develop in this paper. In particular, we allow network nodes to be connected in "clusters", such as asset classes, industries, regions, etc., where shocks are orthogonal across clusters (Sims style orthogonalized identification) but correlated within clusters (Koop-Pesaran-Potter-Shin style generalized identification), so that the ordering of network nodes is relevant across clusters but irrelevant within clusters. After developing the clustered connectedness framework, we apply it in a detailed empirical exploration of sixteen country equity markets spanning three global regions.</details> |
| 2025-02-20 | Modelling the term-structure of default risk under IFRS 9 within a multistate regression framework | Arno Botha, Tanja Verster, Roland Breedt et.al. | [2502.14479](http://arxiv.org/abs/2502.14479) |  | 33 pages, 8192 words, 12 figures | <details><summary>Abstract (click to expand)</summary>The lifetime behaviour of loans is notoriously difficult to model, which can compromise a bank's financial reserves against future losses, if modelled poorly. Therefore, we present a data-driven comparative study amongst three techniques in modelling a series of default risk estimates over the lifetime of each loan, i.e., its term-structure. The behaviour of loans can be described using a nonstationary and time-dependent semi-Markov model, though we model its elements using a multistate regression-based approach. As such, the transition probabilities are explicitly modelled as a function of a rich set of input variables, including macroeconomic and loan-level inputs. Our modelling techniques are deliberately chosen in ascending order of complexity: 1) a Markov chain; 2) beta regression; and 3) multinomial logistic regression. Using residential mortgage data, our results show that each successive model outperforms the previous, likely as a result of greater sophistication. This finding required devising a novel suite of simple model diagnostics, which can itself be reused in assessing sampling representativeness and the performance of other modelling techniques. These contributions surely advance the current practice within banking when conducting multistate modelling. Consequently, we believe that the estimation of loss reserves will be more timeous and accurate under IFRS 9.</details> |
| 2025-02-20 | Causality Analysis of COVID-19 Induced Crashes in Stock and Commodity Markets: A Topological Perspective | Buddha Nath Sharma, Anish Rai, SR Luwang et.al. | [2502.14431](http://arxiv.org/abs/2502.14431) |  |  | <details><summary>Abstract (click to expand)</summary>The paper presents a comprehensive causality analysis of the US stock and commodity markets during the COVID-19 crash. The dynamics of different sectors are also compared. We use Topological Data Analysis (TDA) on multidimensional time-series to identify crashes in stock and commodity markets. The Wasserstein Distance WD shows distinct spikes signaling the crash for both stock and commodity markets. We then compare the persistence diagrams of stock and commodity markets using the WD metric. A significant spike in the $WD$ between stock and commodity markets is observed during the crisis, suggesting significant topological differences between the markets. Similar spikes are observed between the sectors of the US market as well. Spikes obtained may be due to either a difference in the magnitude of crashes in the two markets (or sectors), or from the temporal lag between the two markets suggesting information flow. We study the Granger-causality between stock and commodity markets and also between different sectors. The results show a bidirectional Granger-causality between commodity and stock during the crash period, demonstrating the greater interdependence of financial markets during the crash. However, the overall analysis shows that the causal direction is from stock to commodity. A pairwise Granger-causal analysis between US sectors is also conducted. There is a significant increase in the interdependence between the sectors during the crash period. TDA combined with Granger-causality effectively analyzes the interdependence and sensitivity of different markets and sectors.</details> |

<p align=right>(<a href=#-updated-on-20250314>back to top</a>)</p>

## üìå Deep Learning in Finance

| üìÖ Publish Date | üìñ Title | üë®‚Äçüíª Authors | üîó PDF | üíª Code | üí¨ Comment | üìú Abstract |
|:--------------:|:----------------------------|:------------------|:------:|:------:|:-------:|:--------|
| 2025-03-13 | Unifying monitoring and modelling of water concentration levels in surface waters | Peter B Sorensen, Anders Nielsen, Peter E Holm et.al. | [2503.10285](http://arxiv.org/abs/2503.10285) |  | 41 pages, 11 figures, Developed to support the Danish EPA | <details><summary>Abstract (click to expand)</summary>Accurate prediction of expected concentrations is essential for effective catchment management, requiring both extensive monitoring and advanced modeling techniques. However, due to limitations in the equation solving capacity, the integration of monitoring and modeling has been suffering suboptimal statistical approaches. This limitation results in models that can only partially leverage monitoring data, thus being an obstacle for realistic uncertainty assessments by overlooking critical correlations between both measurements and model parameters. This study presents a novel solution that integrates catchment monitoring and a unified hieratical statistical catchment modeling that employs a log-normal distribution for residuals within a left-censored likelihood function to address measurements below detection limits. This enables the estimation of concentrations within sub-catchments in conjunction with a source/fate sub-catchment model and monitoring data. This approach is possible due to a model builder R package denoted RTMB. The proposed approach introduces a statistical paradigm based on a hierarchical structure, capable of accommodating heterogeneous sampling across various sampling locations and the authors suggest that this also will encourage further refinement of other existing modeling platforms within the scientific community to improve synergy with monitoring programs. The application of the method is demonstrated through an analysis of nickel concentrations in Danish surface waters.</details> |
| 2025-03-13 | A Neumann-Neumann Acceleration with Coarse Space for Domain Decomposition of Extreme Learning Machines | Chang-Ock Lee, Byungeun Ryoo et.al. | [2503.10032](http://arxiv.org/abs/2503.10032) |  | 21 pages, 6 figures, 6 tables | <details><summary>Abstract (click to expand)</summary>Extreme learning machines (ELMs), which preset hidden layer parameters and solve for last layer coefficients via a least squares method, can typically solve partial differential equations faster and more accurately than Physics Informed Neural Networks. However, they remain computationally expensive when high accuracy requires large least squares problems to be solved. Domain decomposition methods (DDMs) for ELMs have allowed parallel computation to reduce training times of large systems. This paper constructs a coarse space for ELMs, which enables further acceleration of their training. By partitioning interface variables into coarse and non-coarse variables, selective elimination introduces a Schur complement system on the non-coarse variables with the coarse problem embedded. Key to the performance of the proposed method is a Neumann-Neumann acceleration that utilizes the coarse space. Numerical experiments demonstrate significant speedup compared to a previous DDM method for ELMs.</details> |
| 2025-03-12 | A Deep Reinforcement Learning Approach to Automated Stock Trading, using xLSTM Networks | Faezeh Sarlakifar, Mohammadreza Mohammadzadeh Asl, Sajjad Rezvani Khaledi et.al. | [2503.09655](http://arxiv.org/abs/2503.09655) |  |  | <details><summary>Abstract (click to expand)</summary>Traditional Long Short-Term Memory (LSTM) networks are effective for handling sequential data but have limitations such as gradient vanishing and difficulty in capturing long-term dependencies, which can impact their performance in dynamic and risky environments like stock trading. To address these limitations, this study explores the usage of the newly introduced Extended Long Short Term Memory (xLSTM) network in combination with a deep reinforcement learning (DRL) approach for automated stock trading. Our proposed method utilizes xLSTM networks in both actor and critic components, enabling effective handling of time series data and dynamic market environments. Proximal Policy Optimization (PPO), with its ability to balance exploration and exploitation, is employed to optimize the trading strategy. Experiments were conducted using financial data from major tech companies over a comprehensive timeline, demonstrating that the xLSTM-based model outperforms LSTM-based methods in key trading evaluation metrics, including cumulative return, average profitability per trade, maximum earning rate, maximum pullback, and Sharpe ratio. These findings mark the potential of xLSTM for enhancing DRL-based stock trading systems.</details> |
| 2025-03-12 | Leveraging LLMS for Top-Down Sector Allocation In Automated Trading | Ryan Quek Wei Heng, Edoardo Vittori, Keane Ong et.al. | [2503.09647](http://arxiv.org/abs/2503.09647) |  |  | <details><summary>Abstract (click to expand)</summary>This paper introduces a methodology leveraging Large Language Models (LLMs) for sector-level portfolio allocation through systematic analysis of macroeconomic conditions and market sentiment. Our framework emphasizes top-down sector allocation by processing multiple data streams simultaneously, including policy documents, economic indicators, and sentiment patterns. Empirical results demonstrate superior risk-adjusted returns compared to traditional cross momentum strategies, achieving a Sharpe ratio of 2.51 and portfolio return of 8.79% versus -0.61 and -1.39% respectively. These results suggest that LLM-based systematic macro analysis presents a viable approach for enhancing automated portfolio allocation decisions at the sector level.</details> |
| 2025-03-12 | AI-based Framework for Robust Model-Based Connector Mating in Robotic Wire Harness Installation | Claudius Kienle, Benjamin Alt, Finn Schneider et.al. | [2503.09409](http://arxiv.org/abs/2503.09409) |  | 6 pages, 6 figures, 4 tables, submitted to the 2025 IEEE 21st   International Conference on Automation Science and Engineering | <details><summary>Abstract (click to expand)</summary>Despite the widespread adoption of industrial robots in automotive assembly, wire harness installation remains a largely manual process, as it requires precise and flexible manipulation. To address this challenge, we design a novel AI-based framework that automates cable connector mating by integrating force control with deep visuotactile learning. Our system optimizes search-and-insertion strategies using first-order optimization over a multimodal transformer architecture trained on visual, tactile, and proprioceptive data. Additionally, we design a novel automated data collection and optimization pipeline that minimizes the need for machine learning expertise. The framework optimizes robot programs that run natively on standard industrial controllers, permitting human experts to audit and certify them. Experimental validations on a center console assembly task demonstrate significant improvements in cycle times and robustness compared to conventional robot programming approaches. Videos are available under https://claudius-kienle.github.io/AppMuTT.</details> |
| 2025-03-12 | Large-scale Thermo-Mechanical Simulation of Laser Beam Welding Using High-Performance Computing: A Qualitative Reproduction of Experimental Results | Tommaso Bevilacqua, Andrey Gumenyuk, Niloufar Habibi et.al. | [2503.09345](http://arxiv.org/abs/2503.09345) |  |  | <details><summary>Abstract (click to expand)</summary>Laser beam welding is a non-contact joining technique that has gained significant importance in the course of the increasing degree of automation in industrial manufacturing. This process has established itself as a suitable joining tool for metallic materials due to its non-contact processing, short cycle times, and small heat-affected zones. One potential problem, however, is the formation of solidification cracks, which particularly affects alloys with a pronounced melting range. Since solidification cracking is influenced by both temperature and strain rate, precise measurement technologies are of crucial importance. For this purpose, as an experimental setup, a Controlled Tensile Weldability (CTW) test combined with a local deformation measurement technique is used.   The aim of the present work is the development of computational methods and software tools to numerically simulate the CTW. The numerical results are compared with those obtained from the experimental CTW. In this study, an austenitic stainless steel sheet is selected. A thermo-elastoplastic material behavior with temperature-dependent material parameters is assumed. The time-dependent problem is first discretized in time and then the resulting nonlinear problem is linearized with Newton's method. For the discretization in space, finite elements are used. In order to obtain a sufficiently accurate solution, a large number of finite elements has to be used. In each Newton step, this yields a large linear system of equations that has to be solved. Therefore, a highly parallel scalable solver framework, based on the software library PETSc, was used to solve this computationally challenging problem on a high-performance computing architecture. Finally, the experimental results and the numerical simulations are compared, showing to be qualitatively in good agreement.</details> |
| 2025-03-12 | A 3d particle visualization system for temperature management | Benoit Lange, Nancy Rodriguez, William Puech et.al. | [2503.09198](http://arxiv.org/abs/2503.09198) |  |  | <details><summary>Abstract (click to expand)</summary>This paper deals with a 3D visualization technique proposed to analyze and manage energy efficiency from a data center. Data are extracted from sensors located in the IBM Green Data Center in Montpellier France. These sensors measure different information such as hygrometry, pressure and temperature. We want to visualize in real-time the large among of data produced by these sensors. A visualization engine has been designed, based on particles system and a client server paradigm. In order to solve performance problems, a Level Of Detail solution has been developed. These methods are based on the earlier work introduced by J. Clark in 1976. In this paper we introduce a particle method used for this work and subsequently we explain different simplification methods we have applied to improve our solution.</details> |
| 2025-03-11 | Capturing Lifecycle System Degradation in Digital Twin Model Updating | Yifan Tang, Mostafa Rahmani Dehaghani, G. Gary Wang et.al. | [2503.08953](http://arxiv.org/abs/2503.08953) |  | 32 pages, 25 figures | <details><summary>Abstract (click to expand)</summary>Digital twin (DT) has emerged as a powerful tool to facilitate monitoring, control, and other decision-making tasks in real-world engineering systems. Online update methods have been proposed to update DT models. Considering the degradation behavior in the system lifecycle, these methods fail to enable DT models to predict the system responses affected by the system degradation over time. To alleviate this problem, degradation models of measurable parameters have been integrated into DT construction. However, identifying the degradation parameters relies on prior knowledge of the system and expensive experiments. To mitigate those limitations, this paper proposes a lifelong update method for DT models to capture the effects of system degradation on system responses without any prior knowledge and expensive offline experiments on the system. The core idea in the work is to represent the system degradation during the lifecycle as the dynamic changes of DT configurations (i.e., model parameters with a fixed model structure) at all degradation stages. During the lifelong update process, an Autoencoder is adopted to reconstruct the model parameters of all hidden layers simultaneously, so that the latent features taking into account the dependencies among hidden layers are obtained for each degradation stage. The dynamic behavior of latent features among successive degradation stages is then captured by a long short-term memory model, which enables prediction of the latent feature at any unseen stage. Based on the predicted latent features, the model configuration at future degradation stage is reconstructed to determine the new DT model, which predicts the system responses affected by the degradation at the same stage. The test results on two engineering datasets demonstrate that the proposed update method could capture effects of system degradation on system responses during the lifecycle.</details> |
| 2025-03-11 | Towards Efficient Parametric State Estimation in Circulating Fuel Reactors with Shallow Recurrent Decoder Networks | Stefano Riva, Carolina Introini, J. Nathan Kutz et.al. | [2503.08904](http://arxiv.org/abs/2503.08904) |  | arXiv admin note: text overlap with arXiv:2409.12550 | <details><summary>Abstract (click to expand)</summary>The recent developments in data-driven methods have paved the way to new methodologies to provide accurate state reconstruction of engineering systems; nuclear reactors represent particularly challenging applications for this task due to the complexity of the strongly coupled physics involved and the extremely harsh and hostile environments, especially for new technologies such as Generation-IV reactors. Data-driven techniques can combine different sources of information, including computational proxy models and local noisy measurements on the system, to robustly estimate the state. This work leverages the novel Shallow Recurrent Decoder architecture to infer the entire state vector (including neutron fluxes, precursors concentrations, temperature, pressure and velocity) of a reactor from three out-of-core time-series neutron flux measurements alone. In particular, this work extends the standard architecture to treat parametric time-series data, ensuring the possibility of investigating different accidental scenarios and showing the capabilities of this approach to provide an accurate state estimation in various operating conditions. This paper considers as a test case the Molten Salt Fast Reactor (MSFR), a Generation-IV reactor concept, characterised by strong coupling between the neutronics and the thermal hydraulics due to the liquid nature of the fuel. The promising results of this work are further strengthened by the possibility of quantifying the uncertainty associated with the state estimation, due to the considerably low training cost. The accurate reconstruction of every characteristic field in real-time makes this approach suitable for monitoring and control purposes in the framework of a reactor digital twin.</details> |
| 2025-03-11 | Nonlinear optimals and their role in sustaining turbulence in channel flow | Dario Klingenberg, Rich R. Kerswell et.al. | [2503.08283](http://arxiv.org/abs/2503.08283) |  |  | <details><summary>Abstract (click to expand)</summary>We investigate the energy transfer from the mean profile to velocity fluctuations in channel flow by calculating nonlinear optimal disturbances,i.e. the initial condition of a given finite energy that achieves the highest possible energy growth during a given fixed time horizon. It is found that for a large range of time horizons and initial disturbance energies, the nonlinear optimal exhibits streak spacing and amplitude consistent with DNS at least at Re_tau = 180, which suggests that they isolate the relevant physical mechanisms that sustain turbulence. Moreover, the time horizon necessary for a nonlinear disturbance to outperform a linear optimal is consistent with previous DNS-based estimates using eddy turnover time, which offers a new perspective on how some turbulent time scales are determined.</details> |
| 2025-03-11 | XAI4Extremes: An interpretable machine learning framework for understanding extreme-weather precursors under climate change | Jiawen Wei, Aniruddha Bora, Vivek Oommen et.al. | [2503.08163](http://arxiv.org/abs/2503.08163) |  |  | <details><summary>Abstract (click to expand)</summary>Extreme weather events are increasing in frequency and intensity due to climate change. This, in turn, is exacting a significant toll in communities worldwide. While prediction skills are increasing with advances in numerical weather prediction and artificial intelligence tools, extreme weather still present challenges. More specifically, identifying the precursors of such extreme weather events and how these precursors may evolve under climate change remain unclear. In this paper, we propose to use post-hoc interpretability methods to construct relevance weather maps that show the key extreme-weather precursors identified by deep learning models. We then compare this machine view with existing domain knowledge to understand whether deep learning models identified patterns in data that may enrich our understanding of extreme-weather precursors. We finally bin these relevant maps into different multi-year time periods to understand the role that climate change is having on these precursors. The experiments are carried out on Indochina heatwaves, but the methodology can be readily extended to other extreme weather events worldwide.</details> |
| 2025-03-10 | Network Analysis of Uniswap: Centralization and Fragility in the Decentralized Exchange Market | Tao Yan, Claudio J. Tessone et.al. | [2503.07834](http://arxiv.org/abs/2503.07834) |  |  | <details><summary>Abstract (click to expand)</summary>The Uniswap is a Decentralized Exchange (DEX) protocol that facilitates automatic token exchange without the need for traditional order books. Every pair of tokens forms a liquidity pool on Uniswap, and each token can be paired with any other token to create liquidity pools. This characteristic motivates us to employ a complex network approach to analyze the features of the Uniswap market. This research presents a comprehensive analysis of the Uniswap network using complex network methods. The network on October 31, 2023, is built to observe its recent features, showcasing both scale-free and core-periphery properties. By employing node and edge-betweenness metrics, we detect the most important tokens and liquidity pools. Additionally, we construct daily networks spanning from the beginning of Uniswap V2 on May 5, 2020, until October 31, 2023, and our findings demonstrate that the network becomes increasingly fragile over time. Furthermore, we conduct a robustness analysis by simulating the deletion of nodes to estimate the impact of some extreme events such as the Terra collapse. The results indicate that the Uniswap network exhibits robustness, yet it is notably fragile when deleting tokens with high betweenness centrality. This finding highlights that, despite being a decentralized exchange, Uniswap exhibits significant centralization tendencies in terms of token network connectivity and the distribution of TVL across nodes (tokens) and edges (liquidity pools).</details> |
| 2025-03-10 | What is missing from existing Lithium-Sulfur models to capture coin-cell behaviour? | Miss. Elizabeth Olisa Monica Marinescu et.al. | [2503.07684](http://arxiv.org/abs/2503.07684) |  | 27 pages, 7 figures, conferences presented: ModVal 2025, ECS 2025 | <details><summary>Abstract (click to expand)</summary>Lithium-sulfur (Li-S) batteries offer a promising alternative to current lithium-ion (Li-ion) batteries, with a high theoretical energy density, improved safety and high abundance, low cost of materials. For Li-S to reach commercial application, it is essential to understand how the behaviour scales between cell formats; new material development is predominately completed at coin-cell level, whilst pouch-cells will be used for commercial applications. Differences such as reduced electrolyte-to-sulfur (E/S) ratios and increased geometric size at larger cell formats contribute to the behavioural differences, in terms of achievable capacity, cyclability and potential degradation mechanisms.   This work focuses on the steps required to capture and test coin-cell behaviour, building upon the existing models within the literature, which predominately focus on pouch-cells. The areas investigated throughout this study, to improve the capability of the model in terms of scaling ability and causality of predictions, include the cathode surface area, precipitation dynamics and C-rate dependence.</details> |
| 2025-03-10 | Simultaneous Energy Harvesting and Bearing Fault Detection using Piezoelectric Cantilevers | P. Peralta-Braz, M. M. Alamdari, C. T. Chou et.al. | [2503.07462](http://arxiv.org/abs/2503.07462) |  |  | <details><summary>Abstract (click to expand)</summary>Bearings are critical components in industrial machinery, yet their vulnerability to faults often leads to costly breakdowns. Conventional fault detection methods depend on continuous, high-frequency vibration sensing, digitising, and wireless transmission to the cloud-an approach that significantly drains the limited energy reserves of battery-powered sensors, accelerating their depletion and increasing maintenance costs. This work proposes a fundamentally different approach: rather than using instantaneous vibration data, we employ piezoelectric energy harvesters (PEHs) tuned to specific frequencies and leverage the cumulative harvested energy over time as the key diagnostic feature. By directly utilising the energy generated from the machinery's vibrations, we eliminate the need for frequent analog-to-digital conversions and data transmission, thereby reducing energy consumption at the sensor node and extending its operational lifetime. To validate this approach, we use a numerical PEH model and publicly available acceleration datasets, examining various PEH designs with different natural frequencies. We also consider the influence of the classification algorithm, the number of devices, and the observation window duration. The results demonstrate that the harvested energy reliably indicates bearing faults across a range of conditions and severities. By converting vibration energy into both a power source and a diagnostic feature, our solution offers a more sustainable, low-maintenance strategy for fault detection in smart machinery.</details> |
| 2025-03-10 | Early signs of stuck pipe detection based on Crossformer | Bo Cao, Yu Song, Jin Yang et.al. | [2503.07440](http://arxiv.org/abs/2503.07440) |  | 33 pages,9 figure | <details><summary>Abstract (click to expand)</summary>Stuck pipe incidents are one of the major challenges in drilling engineering,leading to massive time loss and additional costs.To address the limitations of insufficient long sequence modeling capability,the difficulty in accurately establishing warning threshold,and the lack of model interpretability in existing methods,we utilize Crossformer for early signs of detection indicating potential stuck events in order to provide guidance for on-site drilling engineers and prevent stuck pipe incidents.The sliding window technique is integrated into Crossformer to allow it to output and display longer outputs,the improved Crossformer model is trained using normal time series drilling data to generate predictions for various parameters at each time step.The relative reconstruction error of model is regard as the risk of stuck pipe,thereby considering data that the model can't predict as anomalies,which represent the early signs of stuck pipe incidents.The multi-step prediction capability of Crossformer and relative reconstruction error are combined to assess stuck pipe risk at each time step in advance.We partition the reconstruction error into modeling error and error due to anomalous data fluctuations,furthermore,the dynamic warning threshold and warning time for stuck pipe incidents are determined using the probability density function of reconstruction errors from normal drilling data.The results indicate that our method can effectively detect early signs of stuck pipe incidents during the drilling process.Crossformer exhibits superior modeling and predictive capabilities compared with other deep learning models.Transformer-based models with multi-step prediction capability are more suitable for stuck pipe prediction compared to the current single-step prediction models.</details> |
| 2025-03-10 | An Analytics-Driven Approach to Enhancing Supply Chain Visibility with Graph Neural Networks and Federated Learning | Ge Zheng, Alexandra Brintrup et.al. | [2503.07231](http://arxiv.org/abs/2503.07231) |  | 15 pages, 5 figures, 5 tables, submitted to a journal | <details><summary>Abstract (click to expand)</summary>In today's globalised trade, supply chains form complex networks spanning multiple organisations and even countries, making them highly vulnerable to disruptions. These vulnerabilities, highlighted by recent global crises, underscore the urgent need for improved visibility and resilience of the supply chain. However, data-sharing limitations often hinder the achievement of comprehensive visibility between organisations or countries due to privacy, security, and regulatory concerns. Moreover, most existing research studies focused on individual firm- or product-level networks, overlooking the multifaceted interactions among diverse entities that characterise real-world supply chains, thus limiting a holistic understanding of supply chain dynamics. To address these challenges, we propose a novel approach that integrates Federated Learning (FL) and Graph Convolutional Neural Networks (GCNs) to enhance supply chain visibility through relationship prediction in supply chain knowledge graphs. FL enables collaborative model training across countries by facilitating information sharing without requiring raw data exchange, ensuring compliance with privacy regulations and maintaining data security. GCNs empower the framework to capture intricate relational patterns within knowledge graphs, enabling accurate link prediction to uncover hidden connections and provide comprehensive insights into supply chain networks. Experimental results validate the effectiveness of the proposed approach, demonstrating its ability to accurately predict relationships within country-level supply chain knowledge graphs. This enhanced visibility supports actionable insights, facilitates proactive risk management, and contributes to the development of resilient and adaptive supply chain strategies, ensuring that supply chains are better equipped to navigate the complexities of the global economy.</details> |
| 2025-03-10 | Simulating programmable morphing of shape memory polymer beam systems with complex geometry and topology | Giulio Ferri, Enzo Marino et.al. | [2503.07150](http://arxiv.org/abs/2503.07150) |  |  | <details><summary>Abstract (click to expand)</summary>We propose a novel approach to the analysis of programmable geometrically exact shear deformable beam systems made of shape memory polymers. The proposed method combines the viscoelastic Generalized Maxwell model with the Williams, Landel and Ferry relaxation principle, enabling the reproduction of the shape memory effect of structural systems featuring complex geometry and topology. Very high efficiency is pursued by discretizing the differential problem in space through the isogeometric collocation (IGA-C) method. The method, in addition to the desirable attributes of isogeometric analysis (IGA), such as exactness of the geometric reconstruction of complex shapes and high-order accuracy, circumvents the need for numerical integration since it discretizes the problem in the strong form. Other distinguishing features of the proposed formulation are: i) ${\rm SO}(3)$ -consistency for the linearization of the problem and for the time stepping; ii) minimal (finite) rotation parametrization, that means only three rotational unknowns are used; iii) no additional unknowns are needed to account for the rate-dependent material compared to the purely elastic case. Through different numerical applications involving challenging initial geometries, we show that the proposed formulation possesses all the sought attributes in terms of programmability of complex systems, geometric flexibility, and high order accuracy.</details> |
| 2025-03-10 | Effect of Selection Format on LLM Performance | Yuchen Han, Yucheng Wu, Jeffrey Willard et.al. | [2503.06926](http://arxiv.org/abs/2503.06926) |  |  | <details><summary>Abstract (click to expand)</summary>This paper investigates a critical aspect of large language model (LLM) performance: the optimal formatting of classification task options in prompts. Through an extensive experimental study, we compared two selection formats -- bullet points and plain English -- to determine their impact on model performance. Our findings suggest that presenting options via bullet points generally yields better results, although there are some exceptions. Furthermore, our research highlights the need for continued exploration of option formatting to drive further improvements in model performance.</details> |
| 2025-03-09 | Modular Photobioreactor Fa√ßade Systems for Sustainable Architecture: Design, Fabrication, and Real-Time Monitoring | Xiujin Liu et.al. | [2503.06769](http://arxiv.org/abs/2503.06769) |  | 21 pages, 22 figures, 3 tables | <details><summary>Abstract (click to expand)</summary>This paper proposes an innovative solution to the growing issue of greenhouse gas emissions: a closed photobioreactor (PBR) fa\c{c}ade system to mitigate greenhouse gas (GHG) concentrations. With digital fabrication technology, this study explores the transition from traditional, single function building facades to multifunctional, integrated building systems. It introduces a photobioreactor (PBR) fa\c{c}ade system to mitigate greenhouse gas (GHG) concentrations while addressing the challenge of large-scale prefabricated components transportation. This research introduces a novel approach by designing the fa\c{c}ade system as modular, user-friendly and transportation-friendly bricks, enabling the creation of a user-customized and self-assembled photobioreactor (PBR) system. The single module in the system is proposed to be "neutralization bricks", which embedded with algae and equipped with an air circulation system, facilitating the photobioreactor (PBR)'s functionality. A connection system between modules allows for easy assembly by users, while a limited variety of brick styles ensures modularity in manufacturing without sacrificing customization and diversity. The system is also equipped with an advanced microalgae status detection algorithm, which allows users to monitor the condition of the microalgae using monocular camera. This functionality ensures timely alerts and notifications for users to replace the algae, thereby optimizing the operational efficiency and sustainability of the algae cultivation process.</details> |
| 2025-03-09 | Energy-Adaptive Checkpoint-Free Intermittent Inference for Low Power Energy Harvesting Systems | Sahidul Islam, Wei Wei, Jishnu Banarjee et.al. | [2503.06663](http://arxiv.org/abs/2503.06663) |  |  | <details><summary>Abstract (click to expand)</summary>Deep neural network (DNN) inference in energy harvesting (EH) devices poses significant challenges due to resource constraints and frequent power interruptions. These power losses not only increase end-to-end latency, but also compromise inference consistency and accuracy, as existing checkpointing and restore mechanisms are prone to errors. Consequently, the quality of service (QoS) for DNN inference on EH devices is severely impacted. In this paper, we propose an energy-adaptive DNN inference mechanism capable of dynamically transitioning the model into a low-power mode by reducing computational complexity when harvested energy is limited. This approach ensures that end-to-end latency requirements are met. Additionally, to address the limitations of error-prone checkpoint-and-restore mechanisms, we introduce a checkpoint-free intermittent inference framework that ensures consistent, progress-preserving DNN inference during power failures in energy-harvesting systems.</details> |

<p align=right>(<a href=#-updated-on-20250314>back to top</a>)</p>

## üìå Reinforcement Learning in Finance

| üìÖ Publish Date | üìñ Title | üë®‚Äçüíª Authors | üîó PDF | üíª Code | üí¨ Comment | üìú Abstract |
|:--------------:|:----------------------------|:------------------|:------:|:------:|:-------:|:--------|
| 2023-04-29 | Systematic Review on Reinforcement Learning in the Field of Fintech | Nadeem Malibari, Iyad Katib, Rashid Mehmood et.al. | [2305.07466](http://arxiv.org/abs/2305.07466) |  | 31 pages, 15 figures, 7 tables | <details><summary>Abstract (click to expand)</summary>Applications of Reinforcement Learning in the Finance Technology (Fintech) have acquired a lot of admiration lately. Undoubtedly Reinforcement Learning, through its vast competence and proficiency, has aided remarkable results in the field of Fintech. The objective of this systematic survey is to perform an exploratory study on a correlation between reinforcement learning and Fintech to highlight the prediction accuracy, complexity, scalability, risks, profitability and performance. Major uses of reinforcement learning in finance or Fintech include portfolio optimization, credit risk reduction, investment capital management, profit maximization, effective recommendation systems, and better price setting strategies. Several studies have addressed the actual contribution of reinforcement learning to the performance of financial institutions. The latest studies included in this survey are publications from 2018 onward. The survey is conducted using PRISMA technique which focuses on the reporting of reviews and is based on a checklist and four-phase flow diagram. The conducted survey indicates that the performance of RL-based strategies in Fintech fields proves to perform considerably better than other state-of-the-art algorithms. The present work discusses the use of reinforcement learning algorithms in diverse decision-making challenges in Fintech and concludes that the organizations dealing with finance can benefit greatly from Robo-advising, smart order channelling, market making, hedging and options pricing, portfolio optimization, and optimal execution.</details> |
| 2022-06-28 | Applications of Reinforcement Learning in Finance -- Trading with a Double Deep Q-Network | Frensi Zejnullahu, Maurice Moser, Joerg Osterrieder et.al. | [2206.14267](http://arxiv.org/abs/2206.14267) |  |  | <details><summary>Abstract (click to expand)</summary>This paper presents a Double Deep Q-Network algorithm for trading single assets, namely the E-mini S&P 500 continuous futures contract. We use a proven setup as the foundation for our environment with multiple extensions. The features of our trading agent are constantly being expanded to include additional assets such as commodities, resulting in four models. We also respond to environmental conditions, including costs and crises. Our trading agent is first trained for a specific time period and tested on new data and compared with the long-and-hold strategy as a benchmark (market). We analyze the differences between the various models and the in-sample/out-of-sample performance with respect to the environment. The experimental results show that the trading agent follows an appropriate behavior. It can adjust its policy to different circumstances, such as more extensive use of the neutral position when trading costs are present. Furthermore, the net asset value exceeded that of the benchmark, and the agent outperformed the market in the test set. We provide initial insights into the behavior of an agent in a financial domain using a DDQN algorithm. The results of this study can be used for further development.</details> |
| 2023-02-28 | Recent Advances in Reinforcement Learning in Finance | Ben Hambly, Renyuan Xu, Huining Yang et.al. | [2112.04553](http://arxiv.org/abs/2112.04553) |  | 60 pages, 1 figure | <details><summary>Abstract (click to expand)</summary>The rapid changes in the finance industry due to the increasing amount of data have revolutionized the techniques on data processing and data analysis and brought new theoretical and computational challenges. In contrast to classical stochastic control theory and other analytical approaches for solving financial decision-making problems that heavily reply on model assumptions, new developments from reinforcement learning (RL) are able to make full use of the large amount of financial data with fewer model assumptions and to improve decisions in complex financial environments. This survey paper aims to review the recent developments and use of RL approaches in finance. We give an introduction to Markov decision processes, which is the setting for many of the commonly used RL approaches. Various algorithms are then introduced with a focus on value and policy based methods that do not require any model assumptions. Connections are made with neural networks to extend the framework to encompass deep RL algorithms. Our survey concludes by discussing the application of these RL algorithms in a variety of decision-making problems in finance, including optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising.</details> |

<p align=right>(<a href=#-updated-on-20250314>back to top</a>)</p>

## üìå Time Series Forecasting

| üìÖ Publish Date | üìñ Title | üë®‚Äçüíª Authors | üîó PDF | üíª Code | üí¨ Comment | üìú Abstract |
|:--------------:|:----------------------------|:------------------|:------:|:------:|:-------:|:--------|
| 2025-03-13 | Deep Learning for Time Series Forecasting: A Survey | Xiangjie Kong, Zhenghao Chen, Weiyao Liu et.al. | [2503.10198](http://arxiv.org/abs/2503.10198) |  |  | <details><summary>Abstract (click to expand)</summary>Time series forecasting (TSF) has long been a crucial task in both industry and daily life. Most classical statistical models may have certain limitations when applied to practical scenarios in fields such as energy, healthcare, traffic, meteorology, and economics, especially when high accuracy is required. With the continuous development of deep learning, numerous new models have emerged in the field of time series forecasting in recent years. However, existing surveys have not provided a unified summary of the wide range of model architectures in this field, nor have they given detailed summaries of works in feature extraction and datasets. To address this gap, in this review, we comprehensively study the previous works and summarize the general paradigms of Deep Time Series Forecasting (DTSF) in terms of model architectures. Besides, we take an innovative approach by focusing on the composition of time series and systematically explain important feature extraction methods. Additionally, we provide an overall compilation of datasets from various domains in existing works. Finally, we systematically emphasize the significant challenges faced and future research directions in this field.</details> |
| 2025-03-12 | Minimal Time Series Transformer | Joni-Kristian K√§m√§r√§inen et.al. | [2503.09791](http://arxiv.org/abs/2503.09791) |  | 8 pages, 8 figures | <details><summary>Abstract (click to expand)</summary>Transformer is the state-of-the-art model for many natural language processing, computer vision, and audio analysis problems. Transformer effectively combines information from the past input and output samples in auto-regressive manner so that each sample becomes aware of all inputs and outputs. In sequence-to-sequence (Seq2Seq) modeling, the transformer processed samples become effective in predicting the next output. Time series forecasting is a Seq2Seq problem. The original architecture is defined for discrete input and output sequence tokens, but to adopt it for time series, the model must be adapted for continuous data. This work introduces minimal adaptations to make the original transformer architecture suitable for continuous value time series data.</details> |
| 2025-03-12 | LLM-PS: Empowering Large Language Models for Time Series Forecasting with Temporal Patterns and Semantics | Jialiang Tang, Shuo Chen, Chen Gong et.al. | [2503.09656](http://arxiv.org/abs/2503.09656) |  |  | <details><summary>Abstract (click to expand)</summary>Time Series Forecasting (TSF) is critical in many real-world domains like financial planning and health monitoring. Recent studies have revealed that Large Language Models (LLMs), with their powerful in-contextual modeling capabilities, hold significant potential for TSF. However, existing LLM-based methods usually perform suboptimally because they neglect the inherent characteristics of time series data. Unlike the textual data used in LLM pre-training, the time series data is semantically sparse and comprises distinctive temporal patterns. To address this problem, we propose LLM-PS to empower the LLM for TSF by learning the fundamental \textit{Patterns} and meaningful \textit{Semantics} from time series data. Our LLM-PS incorporates a new multi-scale convolutional neural network adept at capturing both short-term fluctuations and long-term trends within the time series. Meanwhile, we introduce a time-to-text module for extracting valuable semantics across continuous time intervals rather than isolated time points. By integrating these patterns and semantics, LLM-PS effectively models temporal dependencies, enabling a deep comprehension of time series and delivering accurate forecasts. Intensive experimental results demonstrate that LLM-PS achieves state-of-the-art performance in both short- and long-term forecasting tasks, as well as in few- and zero-shot settings.</details> |
| 2025-03-11 | Data Driven Decision Making with Time Series and Spatio-temporal Data | Bin Yang, Yuxuan Liang, Chenjuan Guo et.al. | [2503.08473](http://arxiv.org/abs/2503.08473) |  | This paper is accepted by ICDE 2025 | <details><summary>Abstract (click to expand)</summary>Time series data captures properties that change over time. Such data occurs widely, ranging from the scientific and medical domains to the industrial and environmental domains. When the properties in time series exhibit spatial variations, we often call the data spatio-temporal. As part of the continued digitalization of processes throughout society, increasingly large volumes of time series and spatio-temporal data are available. In this tutorial, we focus on data-driven decision making with such data, e.g., enabling greener and more efficient transportation based on traffic time series forecasting. The tutorial adopts the holistic paradigm of "data-governance-analytics-decision." We first introduce the data foundation of time series and spatio-temporal data, which is often heterogeneous. Next, we discuss data governance methods that aim to improve data quality. We then cover data analytics, focusing on five desired characteristics: automation, robustness, generality, explainability, and resource efficiency. We finally cover data-driven decision making strategies and briefly discuss promising research directions. We hope that the tutorial will serve as a primary resource for researchers and practitioners who are interested in value creation from time series and spatio-temporal data.</details> |
| 2025-03-11 | MFRS: A Multi-Frequency Reference Series Approach to Scalable and Accurate Time-Series Forecasting | Liang Yu, Lai Tu, Xiang Bai et.al. | [2503.08328](http://arxiv.org/abs/2503.08328) |  |  | <details><summary>Abstract (click to expand)</summary>Multivariate time-series forecasting holds immense value across diverse applications, requiring methods to effectively capture complex temporal and inter-variable dynamics. A key challenge lies in uncovering the intrinsic patterns that govern predictability, beyond conventional designs, focusing on network architectures to explore latent relationships or temporal dependencies. Inspired by signal decomposition, this paper posits that time series predictability is derived from periodic characteristics at different frequencies. Consequently, we propose a novel time series forecasting method based on multi-frequency reference series correlation analysis. Through spectral analysis on long-term training data, we identify dominant spectral components and their harmonics to design base-pattern reference series. Unlike signal decomposition, which represents the original series as a linear combination of basis signals, our method uses a transformer model to compute cross-attention between the original series and reference series, capturing essential features for forecasting. Experiments on major open and synthetic datasets show state-of-the-art performance. Furthermore, by focusing on attention with a small number of reference series rather than pairwise variable attention, our method ensures scalability and broad applicability. The source code is available at: https://github.com/yuliang555/MFRS</details> |
| 2025-03-11 | LangTime: A Language-Guided Unified Model for Time Series Forecasting with Proximal Policy Optimization | Wenzhe Niu, Zongxia Xie, Yanru Sun et.al. | [2503.08271](http://arxiv.org/abs/2503.08271) |  |  | <details><summary>Abstract (click to expand)</summary>Recent research has shown an increasing interest in utilizing pre-trained large language models (LLMs) for a variety of time series applications. However, there are three main challenges when using LLMs as foundational models for time series forecasting: (1) Cross-domain generalization. (2) Cross-modality alignment. (3) Error accumulation in autoregressive frameworks. To address these challenges, we proposed LangTime, a language-guided unified model for time series forecasting that incorporates cross-domain pre-training with reinforcement learning-based fine-tuning. Specifically, LangTime constructs Temporal Comprehension Prompts (TCPs), which include dataset-wise and channel-wise instructions, to facilitate domain adaptation and condense time series into a single token, enabling LLMs to understand better and align temporal data. To improve autoregressive forecasting, we introduce TimePPO, a reinforcement learning-based fine-tuning algorithm. TimePPO mitigates error accumulation by leveraging a multidimensional rewards function tailored for time series and a repeat-based value estimation strategy. Extensive experiments demonstrate that LangTime achieves state-of-the-art cross-domain forecasting performance, while TimePPO fine-tuning effectively enhances the stability and accuracy of autoregressive forecasting.</details> |
| 2025-03-06 | TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster | Kanghui Ning, Zijie Pan, Yu Liu et.al. | [2503.07649](http://arxiv.org/abs/2503.07649) |  |  | <details><summary>Abstract (click to expand)</summary>Recently, Large Language Models (LLMs) and Foundation Models (FMs) have become prevalent for time series forecasting tasks. However, fine-tuning large language models (LLMs) for forecasting enables the adaptation to specific domains but may not generalize well across diverse, unseen datasets. Meanwhile, existing time series foundation models (TSFMs) lack inherent mechanisms for domain adaptation and suffer from limited interpretability, making them suboptimal for zero-shot forecasting. To this end, we present TS-RAG, a retrieval-augmented generation based time series forecasting framework that enhances the generalization capability and interpretability of TSFMs. Specifically, TS-RAG leverages pre-trained time series encoders to retrieve semantically relevant time series segments from a dedicated knowledge database, incorporating contextual patterns for the given time series query. Next, we develop a learnable Mixture-of-Experts (MoE)-based augmentation module, which dynamically fuses retrieved time series patterns with the TSFM's representation of the input query, improving forecasting accuracy without requiring task-specific fine-tuning. Thorough empirical studies on seven public benchmark datasets demonstrate that TS-RAG achieves state-of-the-art zero-shot forecasting performance, outperforming TSFMs by up to 6.51% across diverse domains and showcasing desired interpretability.</details> |
| 2025-03-10 | FinTSBridge: A New Evaluation Suite for Real-world Financial Prediction with Advanced Time Series Models | Yanlong Wang, Jian Xu, Tiantian Gao et.al. | [2503.06928](http://arxiv.org/abs/2503.06928) |  | ICLR 2025 Workshop Advances in Financial AI | <details><summary>Abstract (click to expand)</summary>Despite the growing attention to time series forecasting in recent years, many studies have proposed various solutions to address the challenges encountered in time series prediction, aiming to improve forecasting performance. However, effectively applying these time series forecasting models to the field of financial asset pricing remains a challenging issue. There is still a need for a bridge to connect cutting-edge time series forecasting models with financial asset pricing. To bridge this gap, we have undertaken the following efforts: 1) We constructed three datasets from the financial domain; 2) We selected over ten time series forecasting models from recent studies and validated their performance in financial time series; 3) We developed new metrics, msIC and msIR, in addition to MSE and MAE, to showcase the time series correlation captured by the models; 4) We designed financial-specific tasks for these three datasets and assessed the practical performance and application potential of these forecasting models in important financial problems. We hope the developed new evaluation suite, FinTSBridge, can provide valuable insights into the effectiveness and robustness of advanced forecasting models in finanical domains.</details> |
| 2025-03-10 | Enhancing Time Series Forecasting via Logic-Inspired Regularization | Jianqi Zhang, Jingyao Wang, Xingchen Shen et.al. | [2503.06867](http://arxiv.org/abs/2503.06867) |  |  | <details><summary>Abstract (click to expand)</summary>Time series forecasting (TSF) plays a crucial role in many applications. Transformer-based methods are one of the mainstream techniques for TSF. Existing methods treat all token dependencies equally. However, we find that the effectiveness of token dependencies varies across different forecasting scenarios, and existing methods ignore these differences, which affects their performance. This raises two issues: (1) What are effective token dependencies? (2) How can we learn effective dependencies? From a logical perspective, we align Transformer-based TSF methods with the logical framework and define effective token dependencies as those that ensure the tokens as atomic formulas (Issue 1). We then align the learning process of Transformer methods with the process of obtaining atomic formulas in logic, which inspires us to design a method for learning these effective dependencies (Issue 2). Specifically, we propose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method that guides the model to use fewer but more effective dependencies by making the attention map sparse, thereby ensuring the tokens as atomic formulas and improving prediction performance. Extensive experiments and theoretical analysis confirm the effectiveness of Attn-L-Reg.</details> |
| 2025-03-08 | A Novel Distributed PV Power Forecasting Approach Based on Time-LLM | Huapeng Lin, Miao Yu et.al. | [2503.06216](http://arxiv.org/abs/2503.06216) |  | 23 pages, 8 figures | <details><summary>Abstract (click to expand)</summary>Distributed photovoltaic (DPV) systems are essential for advancing renewable energy applications and achieving energy independence. Accurate DPV power forecasting can optimize power system planning and scheduling while significantly reducing energy loss, thus enhancing overall system efficiency and reliability. However, solar energy's intermittent nature and DPV systems' spatial distribution create significant forecasting challenges. Traditional methods often rely on costly external data, such as numerical weather prediction (NWP) and satellite images, which are difficult to scale for smaller DPV systems. To tackle this issue, this study has introduced an advanced large language model (LLM)-based time series forecasting framework Time-LLM to improve the DPV power forecasting accuracy and generalization ability. By reprogramming, the framework aligns historical power data with natural language modalities, facilitating efficient modeling of time-series data. Then Qwen2.5-3B model is integrated as the backbone LLM to process input data by leveraging its pattern recognition and inference abilities, achieving a balance between efficiency and performance. Finally, by using a flatten and linear projection layer, the LLM's high-dimensional output is transformed into the final forecasts. Experimental results indicate that Time-LLM outperforms leading recent advanced time series forecasting models, such as Transformer-based methods and MLP-based models, achieving superior accuracy in both short-term and long-term forecasting. Time-LLM also demonstrates exceptional adaptability in few-shot and zero-shot learning scenarios. To the best of the authors' knowledge, this study is the first attempt to explore the application of LLMs to DPV power forecasting, which can offer a scalable solution that eliminates reliance on costly external data sources and improve real-world forecasting accuracy.</details> |
| 2025-03-08 | Fixing the Pitfalls of Probabilistic Time-Series Forecasting Evaluation by Kernel Quadrature | Masaki Adachi, Masahiro Fujisawa, Michael A Osborne et.al. | [2503.06079](http://arxiv.org/abs/2503.06079) |  | 11 pages, 6 figures | <details><summary>Abstract (click to expand)</summary>Despite the significance of probabilistic time-series forecasting models, their evaluation metrics often involve intractable integrations. The most widely used metric, the continuous ranked probability score (CRPS), is a strictly proper scoring function; however, its computation requires approximation. We found that popular CRPS estimators--specifically, the quantile-based estimator implemented in the widely used GluonTS library and the probability-weighted moment approximation--both exhibit inherent estimation biases. These biases lead to crude approximations, resulting in improper rankings of forecasting model performance when CRPS values are close. To address this issue, we introduced a kernel quadrature approach that leverages an unbiased CRPS estimator and employs cubature construction for scalable computation. Empirically, our approach consistently outperforms the two widely used CRPS estimators.</details> |
| 2025-03-07 | TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting | Shibo Feng, Wanjin Feng, Xingyu Gao et.al. | [2503.05108](http://arxiv.org/abs/2503.05108) |  |  | <details><summary>Abstract (click to expand)</summary>Spiking Neural Networks (SNNs) offer a promising, biologically inspired approach for processing spatiotemporal data, particularly for time series forecasting. However, conventional neuron models like the Leaky Integrate-and-Fire (LIF) struggle to capture long-term dependencies and effectively process multi-scale temporal dynamics. To overcome these limitations, we introduce the Temporal Segment Leaky Integrate-and-Fire (TS-LIF) model, featuring a novel dual-compartment architecture. The dendritic and somatic compartments specialize in capturing distinct frequency components, providing functional heterogeneity that enhances the neuron's ability to process both low- and high-frequency information. Furthermore, the newly introduced direct somatic current injection reduces information loss during intra-neuronal transmission, while dendritic spike generation improves multi-scale information extraction. We provide a theoretical stability analysis of the TS-LIF model and explain how each compartment contributes to distinct frequency response characteristics. Experimental results show that TS-LIF outperforms traditional SNNs in time series forecasting, demonstrating better accuracy and robustness, even with missing data. TS-LIF advances the application of SNNs in time-series forecasting, providing a biologically inspired approach that captures complex temporal dynamics and offers potential for practical implementation in diverse forecasting scenarios. The source code is available at https://github.com/kkking-kk/TS-LIF.</details> |
| 2025-03-06 | Boltzmann convolutions and Welford mean-variance layers with an application to time series forecasting and classification | Daniel Andrew Coulson, Martin T. Wells et.al. | [2503.04956](http://arxiv.org/abs/2503.04956) |  | 40 pages, 7 figures, 11 tables | <details><summary>Abstract (click to expand)</summary>In this paper we propose a novel problem called the ForeClassing problem where the loss of a classification decision is only observed at a future time point after the classification decision has to be made. To solve this problem, we propose an approximately Bayesian deep neural network architecture called ForeClassNet for time series forecasting and classification. This network architecture forces the network to consider possible future realizations of the time series, by forecasting future time points and their likelihood of occurring, before making its final classification decision. To facilitate this, we introduce two novel neural network layers, Welford mean-variance layers and Boltzmann convolutional layers. Welford mean-variance layers allow networks to iteratively update their estimates of the mean and variance for the forecasted time points for each inputted time series to the network through successive forward passes, which the model can then consider in combination with a learned representation of the observed realizations of the time series for its classification decision. Boltzmann convolutional layers are linear combinations of approximately Bayesian convolutional layers with different filter lengths, allowing the model to learn multitemporal resolution representations of the input time series, and which resolutions to focus on within a given Boltzmann convolutional layer through a Boltzmann distribution. Through several simulation scenarios and two real world applications we demonstrate ForeClassNet achieves superior performance compared with current state of the art methods including a near 30% improvement in test set accuracy in our financial example compared to the second best performing model.</details> |
| 2025-03-06 | Hedging with Sparse Reward Reinforcement Learning | Yiheng Ding, Gangnan Yuan, Dewei Zuo et.al. | [2503.04218](http://arxiv.org/abs/2503.04218) |  |  | <details><summary>Abstract (click to expand)</summary>Derivatives, as a critical class of financial instruments, isolate and trade the price attributes of risk assets such as stocks, commodities, and indices, aiding risk management and enhancing market efficiency. However, traditional hedging models, constrained by assumptions such as continuous trading and zero transaction costs, fail to satisfy risk control requirements in complex and uncertain real-world markets.   With advances in computing technology and deep learning, data-driven trading strategies are becoming increasingly prevalent. This thesis proposes a derivatives hedging framework integrating deep learning and reinforcement learning. The framework comprises a probabilistic forecasting model and a hedging agent, enabling market probability prediction, derivative pricing, and hedging.   Specifically, we design a spatiotemporal attention-based probabilistic financial time series forecasting Transformer to address the scarcity of derivatives hedging data. A low-rank attention mechanism compresses high-dimensional assets into a low-dimensional latent space, capturing nonlinear asset relationships. The Transformer models sequential dependencies within this latent space, improving market probability forecasts and constructing an online training environment for downstream hedging tasks.   Additionally, we incorporate generalized geometric Brownian motion to develop a risk-neutral pricing approach for derivatives. We model derivatives hedging as a reinforcement learning problem with sparse rewards and propose a behavior cloning-based recurrent proximal policy optimization (BC-RPPO) algorithm. This pretraining-finetuning framework significantly enhances the hedging agent's performance. Numerical experiments in the U.S. and Chinese financial markets demonstrate our method's superiority over traditional approaches.</details> |
| 2025-03-06 | TimeFound: A Foundation Model for Time Series Forecasting | Congxi Xiao, Jingbo Zhou, Yixiong Xiao et.al. | [2503.04118](http://arxiv.org/abs/2503.04118) |  |  | <details><summary>Abstract (click to expand)</summary>We present TimeFound, an encoder-decoder transformer-based time series foundation model for out-of-the-box zero-shot forecasting. To handle time series data from various domains, TimeFound employs a multi-resolution patching strategy to capture complex temporal patterns at multiple scales. We pre-train our model with two sizes (200M and 710M parameters) on a large time-series corpus comprising both real-world and synthetic datasets. Over a collection of unseen datasets across diverse domains and forecasting horizons, our empirical evaluations suggest that TimeFound can achieve superior or competitive zero-shot forecasting performance, compared to state-of-the-art time series foundation models.</details> |
| 2025-03-05 | Graph-Augmented LSTM for Forecasting Sparse Anomalies in Graph-Structured Time Series | Sneh Pillai et.al. | [2503.03729](http://arxiv.org/abs/2503.03729) |  | 12 pages | <details><summary>Abstract (click to expand)</summary>Detecting anomalies in time series data is a critical task across many domains. The challenge intensifies when anomalies are sparse and the data are multivariate with relational dependencies across sensors or nodes. Traditional univariate anomaly detectors struggle to capture such cross-node dependencies, particularly in sparse anomaly settings. To address this, we propose a graph-augmented time series forecasting approach that explicitly integrates the graph of relationships among time series into an LSTM forecasting model. This enables the model to detect rare anomalies that might otherwise go unnoticed in purely univariate approaches. We evaluate the approach on two benchmark datasets - the Yahoo Webscope S5 anomaly dataset and the METR-LA traffic sensor network - and compare the performance of the Graph-Augmented LSTM against LSTM-only, ARIMA, and Prophet baselines. Results demonstrate that the graph-augmented model achieves significantly higher precision and recall, improving F1-score by up to 10% over the best baseline</details> |
| 2025-03-09 | Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs | Haoran Fan, Bin Li, Yixuan Weng et.al. | [2503.03594](http://arxiv.org/abs/2503.03594) |  | 20 pages, 10 figures | <details><summary>Abstract (click to expand)</summary>While LLMs have demonstrated remarkable potential in time series forecasting, their practical deployment remains constrained by excessive computational demands and memory footprints. Existing LLM-based approaches typically suffer from three critical limitations: Inefficient parameter utilization in handling numerical time series patterns; Modality misalignment between continuous temporal signals and discrete text embeddings; and Inflexibility for real-time expert knowledge integration. We present SMETimes, the first systematic investigation of sub-3B parameter SLMs for efficient and accurate time series forecasting. Our approach centers on three key innovations: A statistically-enhanced prompting mechanism that bridges numerical time series with textual semantics through descriptive statistical features; A adaptive fusion embedding architecture that aligns temporal patterns with language model token spaces through learnable parameters; And a dynamic mixture-of-experts framework enabled by SLMs' computational efficiency, adaptively combining base predictions with domain-specific models. Extensive evaluations across seven benchmark datasets demonstrate that our 3B-parameter SLM achieves state-of-the-art performance on five primary datasets while maintaining 3.8x faster training and 5.2x lower memory consumption compared to 7B-parameter LLM baselines. Notably, the proposed model exhibits better learning capabilities, achieving 12.3% lower MSE than conventional LLM. Ablation studies validate that our statistical prompting and cross-modal fusion modules respectively contribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks. By redefining the efficiency-accuracy trade-off landscape, this work establishes SLMs as viable alternatives to resource-intensive LLMs for practical time series forecasting. Code and models are available at https://github.com/xiyan1234567/SMETimes.</details> |
| 2025-03-04 | SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting | Ting-Ji Huang, Xu-Yang Chen, Han-Jia Ye et.al. | [2503.02836](http://arxiv.org/abs/2503.02836) | **[link](https://github.com/Tingji2419/SeqFusion)** |  | <details><summary>Abstract (click to expand)</summary>Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data. Current zero-shot approaches primarily rely on pre-trained generalized models, with their performance often depending on the variety and relevance of the pre-training data, which can raise privacy concerns. Instead of collecting diverse pre-training data, we introduce SeqFusion in this work, a novel framework that collects and fuses diverse pre-trained models (PTMs) sequentially for zero-shot forecasting. Based on the specific temporal characteristics of the target time series, SeqFusion selects the most suitable PTMs from a batch of pre-collected PTMs, performs sequential predictions, and fuses all the predictions while using minimal data to protect privacy. Each of these PTMs specializes in different temporal patterns and forecasting tasks, allowing SeqFusion to select by measuring distances in a shared representation space of the target time series with each PTM. Experiments demonstrate that SeqFusion achieves competitive accuracy in zero-shot forecasting compared to state-of-the-art methods.</details> |
| 2025-03-04 | Lightweight Channel-wise Dynamic Fusion Model: Non-stationary Time Series Forecasting via Entropy Analysis | Tianyu Jia, Zongxia Xie, Yanru Sun et.al. | [2503.02609](http://arxiv.org/abs/2503.02609) |  |  | <details><summary>Abstract (click to expand)</summary>Non-stationarity is an intrinsic property of real-world time series and plays a crucial role in time series forecasting. Previous studies primarily adopt instance normalization to attenuate the non-stationarity of original series for better predictability. However, instance normalization that directly removes the inherent non-stationarity can lead to three issues: (1) disrupting global temporal dependencies, (2) ignoring channel-specific differences, and (3) producing over-smoothed predictions. To address these issues, we theoretically demonstrate that variance can be a valid and interpretable proxy for quantifying non-stationarity of time series. Based on the analysis, we propose a novel lightweight \textit{C}hannel-wise \textit{D}ynamic \textit{F}usion \textit{M}odel (\textit{CDFM}), which selectively and dynamically recovers intrinsic non-stationarity of the original series, while keeping the predictability of normalized series. First, we design a Dual-Predictor Module, which involves two branches: a Time Stationary Predictor for capturing stable patterns and a Time Non-stationary Predictor for modeling global dynamics patterns. Second, we propose a Fusion Weight Learner to dynamically characterize the intrinsic non-stationary information across different samples based on variance. Finally, we introduce a Channel Selector to selectively recover non-stationary information from specific channels by evaluating their non-stationarity, similarity, and distribution consistency, enabling the model to capture relevant dynamic features and avoid overfitting. Comprehensive experiments on seven time series datasets demonstrate the superiority and generalization capabilities of CDFM.</details> |
| 2025-03-03 | Unify and Anchor: A Context-Aware Transformer for Cross-Domain Time Series Forecasting | Xiaobin Hong, Jiawen Zhang, Wenzhong Li et.al. | [2503.01157](http://arxiv.org/abs/2503.01157) |  | 20 pages, 12 figures, 8 tables, conference under review | <details><summary>Abstract (click to expand)</summary>The rise of foundation models has revolutionized natural language processing and computer vision, yet their best practices to time series forecasting remains underexplored. Existing time series foundation models often adopt methodologies from these fields without addressing the unique characteristics of time series data. In this paper, we identify two key challenges in cross-domain time series forecasting: the complexity of temporal patterns and semantic misalignment. To tackle these issues, we propose the ``Unify and Anchor" transfer paradigm, which disentangles frequency components for a unified perspective and incorporates external context as domain anchors for guided adaptation. Based on this framework, we introduce ContexTST, a Transformer-based model that employs a time series coordinator for structured representation and the Transformer blocks with a context-informed mixture-of-experts mechanism for effective cross-domain generalization. Extensive experiments demonstrate that ContexTST advances state-of-the-art forecasting performance while achieving strong zero-shot transferability across diverse domains.</details> |

<p align=right>(<a href=#-updated-on-20250314>back to top</a>)</p>

